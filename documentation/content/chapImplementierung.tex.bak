\chapter{Implementierung}
%
Ursprünglich war die Idee ein Eigenständiges Programm zu entwickeln, welches Selbstständig Wasserzeichen auf Bildern platziert. Dabei sollten die Gesichter freigelassen werden um die Ästhetik des Bildes nicht zu stören. Aufgrund der limitierten Zeit wird dieser Ansatz reduziert, was ebenfalls ermöglicht ihn flexibler zu gestalten. Indem statt eines eigenständigen Programms ein Modul erstellt wird, ermöglicht man mehr Anwendungszwecke über das einfache Platzieren von Wasserzeichen hinaus.

Bisher wurden für das Laden der Bilder in dieser Arbeit CV2 genutzt, genauer die Funktion \texttt{cv2.imread()}, welche Bilder im BGR-Format lädt. Bei der Implementierung ist allerdings aufgefallen das diese Funktion Probleme mit Umlauten hat, was Problematisch ist wenn Dateipfade geladen werden die diese Enthalten. Also wurde auf die Funktion \texttt{Image.open().convert("RGB")} von PIL gewechselt. Interessanter Weise waren die Ergebnisse von RetinaFace mit RGB-Input, obwohl angegeben wurde das BGR als Input verwendet werden sollte \parencite{lizardNttstar25}. Die confidence Werte waren minimal anders ca. 0.02 und es kam zu weniger weniger False-Negatives, weshalb RGB nun als Input für RetinaFace verwendet wird.

Hauptfunktion des Moduls ist \texttt{cranach\_detector()}, welche gleichzeitig mit RetinaFace, MTCNN und Dlib CNN Bereiche mit Gesichtern auf Bildern markiert und diese in einer Liste zurück gibt. Das Modul liefert Funktionen mit, die einen überprüfen lassen ob sich eine Position oder Fläche auf einem Gesicht befindet, sollten diese allerdings nicht ausreichen so kann man die Ausgegebene Liste für eigene Funktionen verwenden.

Um möglichst viele Verschiedene Anwendungszwecke abzudecken akzeptiert die Funktion \texttt{cranach\_detector()} verschiedene Arten von eingaben:
\begin{itemize}
  \item None: Lässt Nutzer*innen einen Ordner in einem GUI Manuell wählen durch den Iteriert werden soll.
  \item File: Es kann ein Pfad zu einer einzelnen Bild Datei hinterlegt werden welche bearbeitet werden soll.
  \item Path: Wird stattdessen der Pfad eines Ordners übergeben, so werden alle Bilder dieses Ordners zu einer Liste verarbeitet durch die dann iteriert wird.
  \item List: Wenn die interne Funktion unzureichend ist für den Anwendungskontext oder man einfach bereits eine List mit Bilderpfaden hat so kann man diese an das Paket übergeben um diese direkt zu verwenden.
\end{itemize}

Weiter können auch alle Modelle einzeln dazu oder abgeschaltet werden. Sowohl beim Funktionsaufruf, als auch während der Laufzeit. RetinaFace ist dabei per Default aktiviert und alle anderen Modelle deaktiviert. Da RetinaFace bereits gute Ergebnisse liefert reicht es meist alleine aus, so wird Rechenzeit gespart und False-Positives minimiert.

Auch wenn die confidence Grenzwerte optimiert wurden, kann es dennoch sein dass bestimmte Bilder andere Werte benötigen. Aus diesem Grund wurde die Möglichkeit hinzugefügt die confidence Werte während der Laufzeit zu konfigurieren um für jedes Bild und jedes Modell einzeln Grenzwerte zu konfigurieren falls nötig.

Die von den Modellen erkanntem Bereiche werden als Dict in einer Liste gespeichert mit den Attributen x, y, w (width), h (height), model, confidence und image\_name. Diese wird von der der Funktion \texttt{cranach\_detector()} nach durchlaufen aller übergebenen Bilder zurückgegeben, dabei wird die Liste auch weiter intern in einer Variable gespeichert um sie mit anderen internen Funktionen wie \texttt{position\_isIntersecting()} und \texttt{area\_isIntersecting()} direkt zu nutzen. Sollte dies nicht ausreichen, kann auf die ausgegebene Liste zurückgegriffen werden um diese entweder in eigenen Python-Funktionen zu verwenden, zum Beispiel als JSON zu formatieren und so zu exportieren. Das Format in dem RetinaFace seine Ergebnisse ausgibt unterscheidet sich leicht von \gls{mtcnn} und Dlib \gls{cnn}. RetinaFace gibt als Ergebnis die Eckpunkte eines Rechtecks, während die beiden anderen Modelle einen Startpunkt inklusive Breite und Höhe geben. Um die Arbeit mit den gemeinsamen Ergebnissen der Modellen zu erleichtern werden die Ergebnisse von RetinaFace in das Format von \gls{mtcnn} und Dlib \gls{cnn} gebracht, auch wenn das Format von RetinaFace leichter zu verarbeiten ist. Der Grund warum Funktionen in diesem Modul dennoch für Attribute eingaben im Format x, y, breite und höhe erwarten kommt daher, das es im Frontend eher mit Werten im Format x, y, breite und höhe gearbeitet wird. Zudem sind nicht alle Overlays Rechteckig, so dass Eckpunkte nur schwer bestimmt werden könnten.

Die Farben der markierten Gesichter wurden für das Package angepasst so dass sie von Farbenblinden noch gut unterschieden werden können. Als Basis für die Auswahl der Farben diente das Paper von \cite{abs-2107-02270}. Gewählt wurden \texttt{(87, 144, 252)} \textcolor{PetroffBlue}{\rule{1em}{1em}} Blau für RetinaFace, \texttt{(248, 156, 32)} \textcolor{PetroffOrange}{\rule{1em}{1em}} Orange für \gls{mtcnn} und \texttt{(228, 37, 54)} \textcolor{PetroffRed}{\rule{1em}{1em}} Rot für Dlib \gls{cnn}. Blau ist die Farbe die sich am besten eignet um von anderen unterschieden werden zu können. Sie wurde bewusst für RetinaFace gewählt, da das Modell als Basis dient und so am häufigsten mit den anderen Farben in Kontakt kommt. Allerdings können die gewählten Farben auf manchen Bildern etwas schlechter erkannt werden, weshalb die Option hinzugefügt wurde die Markierungen mit dunkleren Farben angezeigt zu bekommen.

Sollten mehrere Modelle das selbe Gesicht markieren so wird nur der kleinste markierte Bereich für das Gesicht behalten. Dafür wird überprüft ob sich zwei markierte Bereiche überschneiden und Fläche mit der Fläche des kleineren Bereiches verglichen. Wenn der überschneidende Bereich 75\% oder mehr der Fläche des kleineren Bereiches ausmacht wird der größere Bereich verworfen. So werden möglichst genaue Ergebnisse behalten, und vermieden das Markierung von Gesichtern die nah beieinander liegen verworfen werden.

Um zu überprüfen ob ein eine Position oder ein Bereich auf einem Gesicht liegt wurden die Funktionen \texttt{position\_isIntersecting()} und \texttt{area\_isIntersecting()} implementiert. Als Argumente erwarten beide Funktionen ein Tupel: (x,y) im Fall von \texttt{position\_isIntersecting()} und (x,y, width, heigth) bei \texttt{area\_isIntersecting()}, zusammen mit dem Dateinamen eines Bildes, welches zuvor schon einmal von \texttt{cranach\_detector()} bearbeitet wurde, damit intern die markierten Bereiche zur Verfügung stehen. Die Funktionen geben True zurück, sollte sich die Position oder der Bereich auf einem Gesicht befinden.
Optional kann auch eine Margin angeben werden, falls ein gewisser Abstand zu Gesichter eingehalten werden soll. Die Funktion gibt dann ebenfalls True zurück sollte sich ein Gesicht innerhalb der Margin um den Bereich oder Punkt befinden.