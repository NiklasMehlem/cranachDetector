\chapter{Einleitung}
%
Im Rahmen der Masterarbeit von \cite{pagelsdorf2024} wurden neue Wasserzeichen für das \gls{cda} entwickelt. Infolgedessen wurde der Ansatz entwickelt, diese automatisiert auf den verschiedenen Bildern der Werke des Archivs zu platzieren. Unter Zuhilfenahme von Gesichtserkennungsmodellen sollten die Gesichter aus ästhetischen Gründen ausgespart werden. Das Problem hierbei ist, dass Gesichtserkennungsmodelle hauptsächlich mit Trainingsdaten bestehend aus Gesichtern realer Menschen entwickelt werden und darauf ausgelegt sind, Gesichter realer Personen zu erkennen. Ziel dieser Arbeit ist das Testen und Vergleichen bestehender Gesichtserkennungsmodelle. Es soll festgestellt werden, ob sich diese für den Einsatz auf historischen Gemälden eignen. Sollten sich mehrere Modelle eignen, wird überprüft, welche für den bestimmten Anwendungskontext priorisiert werden. Hierfür werden die Modelle \textit{Haar-Cascade}, \textit{Caffe}, \textit{MediaPipe}, \textit{Dlib HOG}, \textit{Dlib Landmark}, \textit{Dlib CNN}, \textit{MTCNN}, \textit{Yunet} und \textit{RetinaFace} verglichen. Aus den am besten geeigneten Modellen soll anschließend ein Python-Modul entwickelt werden, das die Gesichtsbereiche eines Bildes ausgibt. Mithilfe dieser Daten soll die Möglichkeit gegeben werden, zu überprüfen, ob sich ein Wasserzeichen potenziell auf einem Gesicht befindet, um so einen Automatisierungsprozess für dessen Platzierung zu ermöglichen.

Im Recherche-Kapitel wird kurz auf die getesteten Modelle eingegangen und ihre grobe Funktionsweise erläutert, um ihre Ergebnisse in einen Kontext einordnen zu können.
Als erster Schritt der Testreihe werden in Stichprobentests die verschiedenen Modelle auf ihre grundsätzliche Eignung geprüft. Es soll festgestellt werden, ob ein getestetes Modell überhaupt in der Lage ist, mit historischen Gemälden zu arbeiten. Modelle, die diese Voraussetzung nicht erfüllen, werden bereits an dieser Stelle ausgeschlossen, um in späteren Tests Zeit und Aufwand zu sparen.
Im Anschluss daran werden Tests mit Bildern unterschiedlicher Auflösungen durchgeführt. Ziel ist es, zu untersuchen, ob die Bildauflösung einen Einfluss auf die Ergebnisse der Modelle hat und welche Auswirkungen dabei zu beobachten sind. Zudem soll auf dieser Basis festgelegt werden, mit welcher Auflösung die Bilder in den folgenden Tests verwendet werden sollten, um möglichst gute Ergebnisse zu erzielen.
Darauf folgend werden die Confidence-Grenzwerte der Modelle im nächsten Test optimiert. Dies soll sicherstellen, dass in der finalen Auswertung die jeweils besten Ergebnisse der Modelle miteinander verglichen werden können, um eine fundierte Entscheidung darüber zu treffen, welche Modelle für das zu entwickelnde Python-Modul verwendet werden sollten.
Der finale Test vergleicht die False-Negatives, False-Positives sowie die Anzahl der Gesichter, die jeweils nur von einem bestimmten Modell erkannt wurden. Das Ziel dieses Tests besteht darin, festzustellen, welche Modelle die zuverlässigsten Ergebnisse liefern und welche sich potenziell ergänzen lassen, um in möglichst allen Bildtypen eine vollständige Gesichtserkennung zu ermöglichen.

Link zum Repository der Arbeit: \url{https://github.com/NiklasMehlem/cranachDetector/tree/main}
