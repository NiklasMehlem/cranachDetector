\chapter{Tests}
Viele Gesichtserkennungsmodelle wurden mit Datensätzen trainiert, die ausschließlich Gesichter von realen Personen enthalten. Hinzu kommt, dass diese Modelle für die Erkennung von Gesichtern realer Personen optimiert wurden. Modelle, die zuverlässig reale Gesichter detektieren, weisen bei der Anwendung auf Bilder historischer Gemälde häufig eine deutlich geringere Erkennungsgenauigkeit auf. Ziel der folgenden Tests ist es, die Eignung und Leistungsfähigkeit verschiedener Gesichtserkennungsmodelle für die Anwendung auf historischen Gemälden zu evaluieren. Begonnen wird mit den Stichprobentests, in welchen ungeeignete Modelle aussortiert werden sollen. Es folgen die Größentests, die dazu dienen, die Ergebnisse bei verschiedenen Auflösungen zu vergleichen. So soll sichergestellt werden, dass weitere Tests Bilder mit einer für die jeweiligen Modelle geeigneten Auflösung verwenden. Im Anschluss werden die \gls{confidence}-Grenzwerte der Modelle optimiert. Dafür werden die \gls{confidence}-Werte für erkannte Gesichter und False-Positives verglichen, um den bestmöglichen Grenzwert zu ermitteln. Im letzten Test werden alle Modelle direkt miteinander verglichen. Hierbei werden die False-Negatives, False-Positives sowie die Gesichter gezählt, die nur von einem Modell erkannt wurden.


\section{Stichprobentests}
Um Zeit und Aufwand zu sparen, soll in den Stichprobentests die Eignung der verschiedenen Gesichtserkennungsmodelle überprüft werden. Ungeeignete Modelle werden am Ende dieser Stichprobentests ausgeschlossen. Hauptkriterium für die Eignung eines Modells ist die Fähigkeit, Gesichter auf historischen Gemälden zuverlässig zu erkennen. Sekundär sollte die Anzahl an False Positives in einem vertretbaren Verhältnis stehen. Ein Modell, das zwar alle Gesichter erkennt, jedoch auch große Teile des restlichen Bildes fälschlicherweise als Gesichter markiert, erlaubt keine präzise Aussage, ob sich ein Overlay auf einem Gesicht befindet. Weitgehend vernachlässigt wird der Aspekt der Rechenzeit. Im Kontext des \gls{cda} gilt es als wichtiger, Gesichter möglichst zuverlässig zu erkennen, als dies möglichst schnell zu tun. Hierfür wurden vier Werke ausgewählt: ein Einzelporträt, ein Zwei-Personen-Porträt, ein Drei-Personen-Porträt sowie ein Gruppenbild. Jedes Modell wird auf jedes der vier Werke angewendet, wodurch sich direkt ein erster Eindruck ergibt, wie gut sich die Modelle im Vergleich eignen. Durch die verschiedenen Bildtypen ist es zudem möglich, dass sich bereits Eignungen für bestimmte Bildkategorien abzeichnen. Schließlich dienen die Tests auch dazu, erste \gls{confidence}-Grenzwerte für die Modelle zu definieren.


\begin{itemize}
	\item \textbf{Haar-Cascade:} Haar-Cascade, genauer \monofett{haarcascade\_frontalface\_default.xml}, eignet sich in keiner Weise. Es scheitert sowohl daran, zuverlässig das Gesicht in einem Einzelporträt zu erkennen, als auch daran, mehrere Gesichter in einem Gruppenbild zu identifizieren. Zudem kommt es häufig zu False-Positives – teilweise werden mehr falsche als tatsächliche Gesichter markiert. Haar-Cascade besitzt keinen direkt einstellbaren \gls{confidence}-Wert, jedoch ein Äquivalent. Selbst bei Variation dieses Wertes liefert das Modell keine zuverlässigen Ergebnisse und scheidet somit bereits an dieser Stelle für weitere Versuche aus. Auffällig ist zudem, dass Haar-Cascade bei identischen Motiven mit höherer Auflösung noch schlechter abschneidet, da vermehrt False-Positives entstehen.
%	
	\item \textbf{Caffe:} Das \gls{caffe}-Modell besteht den Stichprobentest. In Einzel-, Zwei- und Drei-Personen-Porträts werden jeweils alle Hauptgesichter erkannt – zuverlässig und ohne ein einziges False-Positive. Allerdings zeigt das Modell Schwächen bei kleineren Gesichtern oder solchen, die nicht im Fokus des Porträts stehen. Im Gruppenbild wurde kein einziges Gesicht erkannt – auch keine False-Positives. Senkt man den \gls{confidence}-Wert auf 0.2, werden im Drei-Personen-Porträt alle Gesichter erkannt, weiterhin ohne False-Positives. Das Gruppenbild bleibt jedoch eine Schwachstelle: Um Gesichter zu erkennen, müsste der \gls{confidence}-Wert so stark reduziert werden, dass die resultierenden False-Positives die Ergebnisse unbrauchbar machen. Bei höherer Auflösung ändern sich die Resultate kaum – nur im Gruppenbild treten mehr False-Positives auf, was die Problematik unterstreicht. Bei geringerer Auflösung erkennt Caffe weiterhin alle Gesichter korrekt und ohne False-Positives. Im Drei-Personen-Porträt wurde ein Nebengesicht nur halb erkannt. Überraschenderweise wurden im Gruppenbild mit geringer Auflösung tatsächlich Bereiche markiert – einige Gesichter wurden korrekt erkannt, jedoch waren die Bounding-Boxes zu groß, um sinnvoll nutzbar zu sein. Wiederholte Tests mit mittlerer Auflösung (600 × 1130 Pixel) zeigten, dass ein Nebengesicht im Drei-Personen-Porträt nicht erkannt wurde, obwohl es bei höheren und niedrigeren Auflösungen erkannt wurde. Diese Inkonsistenz erschwert die Auswahl einer geeigneten Bildauflösung und könnte ein Grund sein, Caffe letztlich auszuschließen.
%	
	\item \textbf{MediaPipe:} MediaPipe erkennt das Gesicht im Einzelporträt zuverlässig und ohne False-Positives. Dies ist jedoch der einzige bestandene Stichprobentest. In allen anderen Tests – inklusive Zwei-, Drei-Personen-Porträts und Gruppenbild – werden weder Gesichter noch False-Positives markiert. Das deutet darauf hin, dass MediaPipe nur große Gesichter erkennt. Da das Modell im gewünschten Kontext kaum brauchbar ist, wird es nicht weiter getestet. Auch bei höher aufgelösten Bildern bleiben die Ergebnisse identisch.
%	
	\item \textbf{Dlib HOG:} Das \gls{hog}-basierte Modell von dlib zeigt gute Leistungen bei der Erkennung kleiner Gesichter, hat jedoch Probleme mit größeren. Das Gesicht im Einzelporträt wird nur erkannt, wenn der \gls{confidence}-Wert stark reduziert wird – was wiederum zu 0–3 False-Positives führen kann. Die Gesichter in Zwei- und Drei-Personen-Porträts sowie größtenteils im Gruppenbild werden hingegen gut erkannt. Trotz offensichtlicher Schwächen sind die Ergebnisse solide genug für weiterführende Tests. Bei hochauflösenden Bildern erkennt das Modell auch das Einzelporträt, allerdings steigt die Zahl der False-Positives, ähnlich wie bei geringem \gls{confidence}-Wert und niedriger Auflösung. Dies deutet darauf hin, dass der \gls{confidence}-Wert abhängig von der Bildauflösung angepasst werden muss, was den Einsatzaufwand erhöht. Bei geringer Auflösung gibt es im Einzelporträt ein False-Positive, im Zwei- und Drei-Personen-Porträt jedoch keine. Im Gruppenbild verschlechtern sich die Ergebnisse deutlich: Statt 6 Gesichtern mit 3 False-Positives werden nur noch 1 Gesicht und 2 False-Positives erkannt. Das zeigt, dass Gruppenbilder und Porträts separat betrachtet werden sollten. Bei mittlerer Auflösung erkennt das Modell alle Gesichter – außer im Gruppenbild – mit 1–2 False-Positives pro Bild.
%	
	\item \textbf{Dlib HOG Landmark:} Anfangs wurde angenommen, das Landmark-Modell ergänzend zur Überprüfung der Ergebnisse von Dlib \gls{hog} zu verwenden. Ziel war es, False-Positives auszusortieren und dadurch präzisere Ergebnisse zu erzielen. Diese Annahme bestätigt sich nicht. Zwar platziert das Modell die Landmarks korrekt, jedoch führt das Aussortieren basierend auf den Landmark-Daten häufig zur Entfernung korrekter Gesichter statt False-Positives. Das Modell liefert somit keinen Vorteil gegenüber Dlib \gls{hog} und wird daher nicht weiter getestet. Auch hochauflösende Bilder verbessern die Ergebnisse nicht – im Gegenteil, es entstehen häufig mehr False-Positives. Im Drei-Personen-Porträt wurde zwar ein zusätzliches Gesicht erkannt, die Gesamtleistung liegt dennoch unter der vom einfachem Dlib \gls{hog}.
%	
	\item \textbf{Dlib CNN:} Dlib \gls{cnn}, konkret \monofett{mmod\_human\_face\_detector.dat}, ist das langsamste aller getesteten Modelle. Bereits bei Bildern mit einer Größe von 998 × 1314 Pixeln liegt die Bearbeitungszeit bei etwa 20 Sekunden, während alle anderen Modelle unter einer Sekunde bleiben. Die Ergebnisse der Stichprobentests sind jedoch fehlerfrei: Alle Gesichter in Einzel-, Zwei- und Drei-Personen-Porträts wurden erkannt, ohne False-Positives. Im Gruppenbild wurde hingegen nichts erkannt. Aufgrund dieser hohen Zuverlässigkeit wird Dlib \gls{cnn} weiter getestet. Ob sich die lange Bearbeitungszeit durch eine entsprechend hohe Genauigkeit rechtfertigt, muss sich noch zeigen. Bei hochauflösenden Bildern (1200 × 1593 Pixel) bleiben die Ergebnisse gleich, allerdings verdoppelt sich die Bearbeitungszeit auf ca. 40 Sekunden. Bei geringer Auflösung (~400 × 531 Pixel) arbeitet das Modell deutlich schneller, erkennt jedoch nur das Gesicht im Einzelporträt. Bei mittlerer Auflösung werden wieder alle Gesichter – bis auf das Nebengesicht im Drei-Personen-Porträt – erkannt. Anders als viele andere Modelle scheint Dlib \gls{cnn} mit höheren Auflösungen besser zu funktionieren – zum Preis höherer Rechenzeit.
%	
	\item \textbf{MTCNN:} \gls{mtcnn} besteht die Stichprobentests für Einzel-, Zwei- und Drei-Personen-Porträts fehlerfrei. Im Gruppenbild werden einige Gesichter erkannt, allerdings nur solche mit \gls{confidence} > 0.5. Es gibt keine False-Positives. Somit wird MTCNN weiter getestet. Bei höherer Auflösung bleibt die durchschnittliche \gls{confidence} gleich, es treten jedoch in einzelnen Fällen 1–3 False-Positives auf. Im Gruppenbild werden mehr Gesichter erkannt (6 von 13), jedoch keine neuen False-Positives. Einige dieser False-Positives haben hohe \gls{confidence}-Werte (~0.85), was die Auswahl eines optimalen Schwellwerts erschwert. Bei geringer Auflösung erkennt MTCNN weiterhin zuverlässig alle Gesichter in Einzel-, Zwei- und Drei-Personen-Porträts mit einer \gls{confidence} von 1.0 und ohne False-Positives. Im Gruppenbild wird nichts markiert. Bei mittlerer Auflösung bleibt das Verhalten stabil – im Gruppenbild werden vier Gesichter mit ca. 0.85 \gls{confidence} erkannt.
%	
	\item \textbf{Yunet:} Das Yunet-Modell (\monofett{face\_detection\_yunet\_2023mar.onnx}) ist ohne Konfiguration sehr strikt. Es erkennt Gesichter mit hoher Präzision, aber auch sehr selektiv. Nach Einstellung des \gls{confidence}-Wertes auf 0.8 werden alle Gesichter in Einzel-, Zwei- und Drei-Personen-Porträts erkannt, jedoch nur wenige im Gruppenbild. Ob 0.8 optimal ist, wird sich in weiteren Tests zeigen. Bei höherer Auflösung verbessert sich die \gls{confidence} der erkannten Gesichter leicht. Im Gruppenbild verändert sich die Erkennung – ein vorher erkanntes Gesicht fehlt, ein anderes wird zusätzlich erkannt. Es gibt weiterhin keine False-Positives. Bei geringer Auflösung erkennt Yunet alle Gesichter bis auf die im Gruppenbild, wo kein Gesicht markiert wird. Auch bei mittlerer Auflösung bleiben die Ergebnisse identisch zu jenen bei niedriger Auflösung.
%	
	\item \textbf{RetinaFace (CPU):} Verwendet wird RetinaFace mit ResNet-50-\gls{backbone} und CPU-Nutzung, da GPU lediglich die Geschwindigkeit, nicht aber die Genauigkeit erhöht. So bleiben die Ergebnisse vergleichbar. RetinaFace erzielt in den Stichprobentests die besten Ergebnisse aller Modelle: Alle Gesichter in Einzel-, Zwei- und Drei-Personen-Porträts werden ohne False-Positives erkannt. Im Gruppenbild werden 10 von 13 Gesichtern identifiziert – ein bisher unerreichter Wert. Es treten zwei False-Positives auf, bei denen Pferdegesichter markiert wurden. Bei höherer Auflösung bleiben die Ergebnisse stabil, die \gls{confidence}-Werte ändern sich nur minimal. Im Gruppenbild wurde ein schwach erkanntes Gesicht nicht erneut erkannt. Bei geringer Auflösung erkennt RetinaFace weiterhin alle Gesichter in Einzel-, Zwei- und Drei-Personen-Porträts korrekt. Die Anzahl erkannter Gesichter im Gruppenbild sinkt auf 8 von 13, bleibt damit jedoch konkurrenzlos hoch. Auch bei mittlerer Auflösung bleiben die Erkennungsergebnisse stabil und präzise.
\end{itemize}

%\section{Haar-Cascade}
%Haar-Cascade, genauer \monofett{haarcascade\_frontalface\_default.xml}, eignet sich in keiner Weise. Es scheitert sowohl darin zuverlässig das Gesicht in einem Portrait zu erkennen, als auch darin mehrere Gesichter in einem Gruppen Bild zu erkennen. Zudem kommt es oft zu false-positives. Teilweise werden dadurch mehr false-positives als tatsächliche Gesichter markiert. Haar Cascade hat nicht direkt einen \gls{confidence} Wert den man bearbeiten kann aber ein äquivalent, jedoch ist selbst mit verschiedenen Werten Haar Cascade nicht in der Lage zuverlässige Ergebnisse zuliefern und scheidet damit bereits hier für weitere Versuche aus.
%Anzumerken ist ebenfalls das Haar-Cascade bei gleichen Motiv mit höherer Auflösung noch schlechter abschneidet, in dem es zu mehr false-positives kommt.
%
%\section{Caffe}
%\gls{caffe} besteht den Stichproben Test. Beim Bei Einzel-, Zwei- und Drei-Personen-Porträts schafft es jeweils alle 'Hauptgesichter' zu erkennen. Zusätzlich ist es dabei auch sehr sicher ohne ein einziges false-positiv bei allen Stichproben Tests. Allerdings scheint es dafür mit kleineren Gesichtern, oder Gesichtern die nicht Hauptfokus des Portraits sind Probleme zu haben. So wurde im Gruppen Bild nicht ein Gesicht markiert, auch kein false-positiv. Reduziert man den \gls{confidence} Wert auf 0.2 so ist \gls{caffe} auch in der Lage alle Gesichter im Drei-Personen-Porträt zu erkennen, weiter ohne false-positives. Das Gruppenbild hingegen bleibt der Schwachpunkt des Modells. Um Gesichter im Gruppenbild zu erkennen muss der \gls{confidence} Wert so weit reduziert werden, dass es zu so vielen false-positives kommt das die Ergebnisse unbrauchbar werden. Verwendet man Bilder mit höherer Auflösung so werden gleiche Ergebnisse in den Stichproben Tests erzielt. Lediglich beim Gruppenbild kommt es zu mehr False-Positives. Einen großen Unterschied macht dies allerdings nicht, da das \gls{caffe} Modell schon zuvor Schwierigkeiten mit diesem Bild hatte. Verwendet man Bilder mit geringer Auflösung so schafft es \gls{caffe} weiter alle Gesichter zu erkennen ohne False-Positves, wenn auch im Drei-Personen-Porträt ein Nebengesicht nur halb getroffen wurde. Überraschender weiße wurden im Gruppenbild mit geringer Auflösung tatsächlich Bereiche maskiert. Auch wenn dabei einige Gesichter korrekt markiert wurden, waren die markierten Bereiche viel zu groß, als das sie sinnvoll wären. Überraschenderweise als der Stichproben-Test mit Bildern mittlerer Auflösung (600 x 1130 Pixel) wiederholt wurde wurde im Drei-Personen-Porträt das Nebengesicht nicht erkannt, obwohl es bei größeren und kleineren Bild Größen zuvor erkannt wurde. Diese inkonsistent wird es schwerer machen eine geeignete Bildgröße für die Tests zu finden, oder es könnte ein Grund werden warum \gls{caffe} am Ende doch verworfen wird.
%
%\section{MediaPipe}
%MediaPipe schafft es beim Einzelporträt das Gesicht sicher zu erkennen ohne false-positives. Dies ist aber auch der einzige Stichproben Test den MediaPipe besteht. Bei allen anderen Tests wird von MediaPipe nichts markiert, weder Gesichter noch false-positives. Das lässt vermuten, dass MediaPipe nur in der Lage ist große Gesichter zu erkennen. Da dieses Modell sehr ineffektiv für den gewünschten Kontext scheint wird es hier aussortiert und wird nicht weiter getestet. In Stichproben Tests mit höher auflösenden Bildern erzielt MediaPipe Identische Ergebnisse.
%
%\section{Dlib HOG}
%Das \gls{hog} basierte Gesichtsdetektionsmodell von dlib zeigt in den Stichproben Tests, dass es gut darin ist kleine Gesichter zu erkennen aber Probleme mit größeren hat. So hat es sehr große Probleme das Gesicht beim Einzelporträt zu erkennen, ohne dass man den \gls{confidence} Wert ins unbrauchbare reduziert. Je nach \gls{confidence} Wert kommt es auch noch zu kleinen Mengen (ca. 0 bis 3) von false-positives. Doch wurden die Gesichter im Zwei- und Drei-Personen-Porträt sowie größten Teils im Gruppenbild gut erkannt. Das Modell weißt zwar offensichtliche Schwäche auf, allerdings sind die Ergebnisse gut genug das es weiter getestet wird. Es könnte sich als nützliche alternative für Bilder herausstellen bei denen andere Modelle Probleme haben die Gesichter zu erkennen. Verwendet man hochauflösende Bilder in den Stichproben Tests so schafft es \gls{hog} mit gleicher \gls{confidence} das Gesicht im Einzelporträt zu erkennen, allerdings erhöht sich die Anzahl an false-positives. Die Ergebnisse erinnern somit an jene mit geringerem \gls{confidence} wert bei Bildern mit geringere Auflösung. Es scheint so als müsste der \gls{confidence} Wert von \gls{hog} in abhängigkeit der Bildauflösung eingestellt werden. Sollte dies der Fall sein könnte es das Modell deutlich unattraktiver durch den erhöhten Aufwand in der Verwendung machen. Bei einem weiteren Test mit Bildern geringer Auflösung ergibt sich beim Einzelporträt weiter nur ein false-positiv, dafür keine False-Positives bei den Zwei- und Drei-Personen-Porträts. Jedoch gibt es beim Gruppen Bild eine deutliche Verschlechterung aus 6 erkannten Gesichtern und 3 False-Positives wurden 1 erkanntes Gesicht und 2 False-Positives. Zugegeben durch die geringe Auflösung sind die Gesichter des Gruppen Bilds relativ schwer erkennbar. Daran wird gezeigt das Portraits und Gruppenbilder unterschiedlich behandelt werden sollten und sich fürs erste weiter auf Portraits fokussiert werden sollte. Testet man Dlib \gls{hog} mit Bildern mittlerer Auflösung, so werden in allen Bildern, bis auf dem Gruppenbild, alle Gesichter erkannt. Dabei kam es in jedem Bild auch zu 1-2 False-Positives.
%
%\section{Dlib HOG Landmark}
%Vor der Recherche wurde davon ausgegangen das das Landmark Modell seine Eingaben überprüft, so das genauere Ergebnisse im Vergleich zum einfachen Dlib \gls{hog}. Dies scheint nicht der Fall zu sein, allerdings können die markierten Landmarks analysiert werden um so von Dlib \gls{hog} makierte false-positives auszusortieren. Mit diesem Ansatz wird Dlib \gls{hog} Landmark in den Stichproben-Tests untersucht ob es tatsächlich genauer sein kann.
%Da in dieser Arbeit Dlib \gls{hog} verwendet wurde um die \gls{boundingbox}es für das Landmark Modell zu bestimmen sind die Ergebnisse beider Modelle identisch. Das Landmark Modell hat dabei keine Probleme die Landmarks der identifizierten Gesichter korrekt zu platzieren. Die markierten Gesichter wurden nun noch einmal überprüft ob false-positives auszusortieren für genauere Ergebnisse im Vergleich zu Dlib \gls{hog} ohne Landmark. Allerdings wurde dabei meist die korrekten Gesichter aussortiert statt false-positives. Es wurde auch false-positives aussortiert, was jedoch irrelevant ist wenn das Modell Gesichter nur schlecht erkennt. Dlib \gls{hog} Landmark wird daher nicht weiter getestet, da es im Vergleich zu Dlib \gls{hog} keinen Mehrwert liefert. Hochauflösende Bilder liefern dabei auch keine besseren Ergebnisse, sondern in den meisten Fällen eher mehr flase-positives. Im Drei-Personen-Porträt wurde zwar 1 Gesicht mehr erkannt, was jedoch immer noch deutlich Schlechter als einfaches Dlib \gls{hog} ist, welches alle Gesichter im Drei-Personen-Porträt erkannt hat.
%
%\section{Dlib CNN}
%Dlib \gls{cnn}, genauer \monofett{mmod\_human\_face\_detector.dat}, ist das spürbar langsamste Modell von allen bisher getesteten. In der Dokumentation wurde bereits über eine hohe Latenz berichtet, allerdings ist diese deutlich spürbarer als erwartet \parencite{cnnFaceDetectoroD}. Bereits bei Bildern der Größe 998 x 1314 Pixel muss für ca. 20 Sekunden auf ein Ergebnis gewartet werden, während die anderen Modelle unter einer Sekunde bleiben. Das Ergebnis der Stichproben Tests ist dafür Fehlerlos. Bei Einzel-, Zwei- und Drei-Personen-Porträts wurden alle Gesichter erkannt ohne false-positives. Nur beim Gruppenbild wurde kein Gesicht oder false-positiv erkannt. Mit eine so zuverlässigen Ergebnis wird Dlib \gls{cnn} weiter getestet und verglichen. Am ende muss sich zeigen, dass die deutlich längere Bearbeitungszeit sich auch in deutlich besserer Zuverlässigkeit widerspiegelt um sie zu rechtfertigen. Verwendet man hochauflösende Bilder, hier 1200 x 1593 Pixel, so bleiben die Ergebnisse gleich. Lediglich die Warte Zeit erhöht sich deutlich. Aus ca. 20 Sekunden Bearbeitungszeit wurden ca. 40. Es handelt sich hierbei zwar nur um Stichproben, allerdings könnte dies der große Nachteil von \gls{cnn} sein wenn bei bereits 20\% größeren sich die Bearbeitungszeit verdoppelt wenn bereits die Ursprüngliche Bearbeitungszeit deutlich über dem durchschnitt der anderen getesteten Modelle liegt. Verwendet man Bilder mit geringer Auflösung ca. 400 x 531 Pixel so arbeitet das Modell mit vergleichbarer Geschwindigkeit verglichen mit den anderen Modellen. Allerdings war es dann nur noch in der Lage Gesichter im Einzelporträt zu erkennen, auf allen anderen Bildern wurde nichts mehr markiert. Bei Stichprobentests mit Bildern mittlerer Auflösung, werden wieder alle Gesichter bei Einzel-, Zwei- und Drei-Personen-Porträts gefunden bis auf das Nebengesicht im Drei-Personen-Porträt. Anders als bei den meisten anderen Modellen die getestet wurden, scheint Dlib \gls{cnn} mit größeren Bildern besser zu arbeiten. Nachteil bleibt das dadurch die Bearbeitungszeit weiter hoch bleibt um von Dlib \gls{cnn}s Genauigkeit zu nutzen.
%
%\section{MTCNN}
%\gls{mtcnn} hat den Stichproben Test für Einzel-, Zwei- und Drei-Personen-Porträts fehlerlos bestanden. Beim Gruppen Bild wurden bloß ein paar Gesichter erkannt, dabei sollten nur Ergebnisse mit > 0.5 \gls{confidence} makiert werden. Es gab des weiteren nicht einen false-positiv. Somit wird \gls{mtcnn} sicher weiter getestet. Verwendet man Bilder mit höherer Auslösung so zeigt sich im Stichproben-Test das die \gls{confidence} erkannter Gesichter im schnitt gleich bleibt, allerdings kommt es bei manchen Bildern zu 1 bis 3 false-positives. Im Gruppen Bild hingegen wurden ohne weitere false-positives bei höherer Auflösung mehr Gesichter erkannt, wenn auch nur 6 von 13 insgesamt. Die false-positives bei höherer Auflösung haben sehr hohe \gls{confidence} Werte (ca. 0.85) was das bestimmen eines besserer geeigneten \gls{confidence} Wertes erschwert. In den kommenden Tests muss sich zeigen ob \gls{mtcnn} weiter verlässlich bleibt, oder ob sich doch false-positives unvermeidlich dazu mischen. Werden Bilder mit geringer Auflösung getestet so erkennt \gls{mtcnn} weiter alle Gesichter in Einzel-, Zwei- und Drei-Personen-Porträts korrekt markiert noch dazu mit 1.0 \gls{confidence}. Weiter gibt es keine False-Positves, und im Gruppen Bild werden keine Bereiche markiert. In Stichprobentests mit mittlerer Auflösung bleiben die Ergebnisse größtenteils Identisch, nur wurden im Gruppenbild 4 Gesichter erkannt mit ca. 0.85 \gls{confidence}.
%
%\section{Yunet}
%Das Yunet Modell, in diesem fall \monofett{face\_detection\_yunet\_2023mar.onnx}, ist ohne weitere Einstellungen sehr streng. Bei den Stichproben Test kam es zu keinen false-positives, allerdings wurde in manchen Bildern nicht alle Gesichter markiert. Nachdem der \gls{confidence} Wert auf 0.8 eingestellt wurde, wurde Problemlos alle Gesichter des Einzel-, Zwei- und Drei-Personen-Porträts erkannt. Aus dem Gruppen Bild wurden nur wenige Gesichter markiert. Ob 0.8 der optimale Wert ist wird sich zeigen wenn Yunet intensiver getestet wird. Aufgrund seiner Genauigkeit wird Yunet weiter getestet. Nutzt man Bilder mit höherer Auflösung in den Stichproben Tests so verbessert sich der \gls{confidence} Wert der gefundenen Gesichter. Beim Gruppenbild wurde ein zuvor erkanntes Gesicht nicht erkannt, ein vorher nicht erkanntes Gesicht dann wiederum schon. Weiter gab es bei keinem der Stichproben Tests mit höherer Auflösung ein false-positiv, womit Yunet ein sicherer Kandidat bleibt für die kommenden Tests. Im Stichprobentest mit Bildern geringer Auflösung findet Yunet weiter alle Geischter in allen Bildern bis auf im Gruppenbild wo es keines mehr erkennt. Werden Bildern mit mittlerer Auflösung verwendet so bleiben die Ergebnisse Identisch zu denen aus den Test geringer Auflösung.
%
%\section{RetinaFace (CPU)}
%Verwendet wird in dieser Arbeit RetinaFace mit ResNet-50 \gls{backbone} und CPU Einsatz. Grund dafür ist, dass RetinaFace mit GPU Einsatz lediglich schneller und nicht genauer sein soll. So bleiben die Werte von RetinaFace später vergleichbarer. Die Option das mit einer geeigneten GPU schnellere Ergebnisse erzielt werden können, kann später bei der Auswertung noch berücksichtigt werden. Was die Ergebnisse des Stichproben Tests angeht hat RetinaFace das beste Ergebnisse aller Modelle bisher. Alle Gesichter ohne false-positives im Einzel-, Zwei- und Drei-Personen-Porträt erkannt. Noch dazu wurden 10 der 13 Gesichter im Gruppenbild erkannt, wo die besten Ergebnisse bisher ca. 6 Gesichter waren. Jedoch sei anzumerken das es 2 false-positives gab bei denen die Gesichter von Pferden markiert wurden. Ob RetinaFace diese Quote beibehalten kann wird sich in den folgenden Tests ergeben. RetinaFace bleibt bei den Stichproben Tests mit höherer auflösenden Bildern konstant. \gls{confidence} Werte verbessern sich leicht oder verschlechtern sich um wenige 0.05 Punkte. Weiter gibt es auch keine neuen false-positives. Lediglich beim Gruppenbild wurde ein Gesicht weniger erkannt, dieses hatte aber auch schon im Test zuvor den geringsten \gls{confidence} Wert von allen erkannten Gesichtern. Im Test mit Bildern mit geringer Auflösung schneidet RetinaFace weiter am besten ab. Es gab keine False-Positives und es wurden alle Gesichter im Einzel-, Zwei- und Drei-Personen-Porträt erkannt. Die Anzahl erkannter Gesichter sankt zwar auf 8 von 13 im Gruppenbild, ist aber bei weitem das beste Ergebnis mit dieser Auflösung wo andere Modelle meist nichts mehr erkannt haben. Im Stichprobentest mit Bildern mittlerer Auflösung werden weiter alle Gesichter im Einzel-, Zwei- und Drei-Personen-Porträt fehlerfrei erkannt. Im Gruppen Bild werden 9 von 13 Gesichtern erkannt, sowie die zwei false-positivs der Pferdegesichter.

\section{Größentests}
Das \gls{cda} speichert Bilder von Werken in drei Größen: Small, Medium und Large. Da jedes Werk sein eigenes Format hat, haben nicht alle Bilder die exakt gleiche Auflösung. Small-Bilder haben 400~px Breite, Medium-Bilder haben 600~px Breite, Large-Bilder haben 1200~px Breite. Während der Stichprobentests wurde bereits ein wenig mit Bildern verschiedener Auflösungen experimentiert, die Ergebnisse waren jedoch nicht sehr übersichtlich oder eindeutig, sodass nochmal alle verbliebenen Modelle mit allen drei Größen getestet werden.

%Hier Tabell hin!
Als Ergebnis wird festgelegt, dass Large-Bilder sich am besten eignen. Zwar weisen sie den Nachteil auf, dass sie die meisten False-Positives generieren, jedoch werden aber auch alle Gesichter auf ihnen erkannt, was relevanter ist. Des Weiteren wird davon ausgegangen, dass einige dieser False-Positives darauf zurückzuführen sind, dass die \gls{confidence}-Grenzwerte noch nicht optimiert wurden. Dlib \gls{hog} wird verworfen, da es während der Tests im Vergleich deutlich mehr False-Positives gezeigt hat und es bereits genug Modelle mit akzeptablen Werten gibt, sodass das Modell als Kandidat nicht mehr relevant ist.

\section{Confidencetests}
Zur bestmöglichen Repräsentation der Modelle werden alle \gls{confidence}-Grenzwerte bzw. Score-Threshholds der Modelle angepasst. Zunächst wird kein Grenzwert gesetzt und die Ausgaben beobachtet. Dabei wird explizit auf die Werte des kleinsten \gls{confidence}-Wertes für ein erkanntes Gesicht und des höchsten \gls{confidence}-Wertes für ein False-Positiv geachtet. Sollten sich diese überschneiden, so wird mithilfe des Kontextes der anderen Ergebnisse bestimmt, welcher \gls{confidence}-Grenzwert sich für das jeweilige Modell am besten eignet zur Gesichtserkennung auf historischen Gemälden. Hier sei noch einmal angemerkt, dass jedes Modell seine eigene Implementierung für \gls{confidence}-Werte hat. Ein höherer Wert bedeutet jedoch nicht zwangsläufig, dass ein Modell besser ist – er gibt lediglich an, wie sicher sich das Modell ist, ein Gesicht erkannt zu haben.

\begin{itemize}
	\item \textbf{Caffe:} Die Ergebnisse von \gls{caffe} waren bei -1 \gls{confidence}-Grenzwert viel zu unkenntlich, also wurde der Test wiederholt. Im zweiten Anlauf wurden alle Markierungen mit einem \gls{confidence}-Wert > 0{,}1 akzeptiert, da alle Ergebnisse unter diesem Wert aufgrund der riesigen Mengen an False-Positives unbrauchbar wären.  
Minimaler \gls{confidence}-Wert für erkannte Gesichter beim Einzelporträt war 0{,}11, während der maximale False-Positive-Wert 0{,}21 ist. Der Wert wurde bei einem Bild gemessen, alle anderen erreichten einen Wert von 1{,}00 oder ca. 0{,}80. Da nur ein Bruchteil des Cranach-Archivs aufgrund der limitierten Zeit getestet werden kann, wird der Wert nicht als Ausreißer, sondern als gleichwertig betrachtet, da es im restlichen Archiv bestimmt ähnliche Bilder zum 0{,}11-Kandidaten gibt.  
Ergebnisse des Tests mit Zwei-Personen-Porträts waren deutlich weniger konstant als im letzten Test. Geringster Wert für ein erkanntes Gesicht war 0{,}14, 0{,}13 wenn Nebengesichter mitgezählt werden. Allerdings gab es ein großes False-Positive, sowohl vom Wert als auch von der Fläche her, mit 0{,}4.  
Der Test mit Drei-Personen-Porträts verlief sehr schlecht für \gls{caffe}. Der geringste erkannte Wert ist 0{,}1, es ist aber auch sehr wahrscheinlich, dass der eigentliche Wert noch geringer ist, da in manchen Bildern nicht alle Gesichter erkannt wurden. Auch gab es eine sehr große Menge an False-Positives, höchster Wert in diesem Test: 0{,}28.  
Mit minimaler Gesichtserkennung bei \gls{confidence} von 0{,}1 und maximalem False-Positive-\gls{confidence} von 0{,}4 ist das Bestimmen eines optimalen Grenzwertes sehr schwierig. Nach mehreren weiteren Tests wurde entschieden, den Grenzwert auf 0{,}14 zu setzen. Leider werden damit einige Ergebnisse von erkannten Gesichtern verworfen, allerdings gibt es bis 0{,}13 noch große Mengen an False-Positives, was die Gesamtergebnisse brauchbarer macht.
%	
	\item \textbf{Dlib CNN:} Dlib \gls{cnn}s Tests mit Einzelporträts haben selbst bei einem Grenzwert von -1 keine False-Positives gezeigt. Der minimale Wert für erkannte Gesichter lag bei 1{,}03.  
Im Test mit Zwei-Personen-Porträts gab es weiterhin keine False-Positives, allerdings wurden auch einige Neben- sowie Hauptgesichter nicht erkannt. 0{,}70 war der kleinste gemessene Wert für ein Gesicht.  
Weiter wurden im Test mit Drei-Personen-Porträts keine False-Positives erkannt, aber auch teils manche Gesichter nicht erkannt. Der geringst gemessene Wert für ein erkanntes Gesicht war in diesem Test 0{,}97, womit 0{,}7 der gesamt niedrigste Wert für Dlib \gls{cnn} ist. Da bisher keine False-Positives erkannt wurden und Dlib \gls{cnn} sehr streng scheint, wird der verwendete Grenzwert für Dlib \gls{cnn} 0{,}6 sein.
%	
	\item \textbf{MTCNN:} \gls{mtcnn} ist sehr sicher durch den Test mit Einzelporträts gekommen. Keine False-Positives und ein minimaler \gls{confidence}-Wert bei der Gesichtserkennung von 0{,}99. Generell sind alle Werte konstant zwischen 0{,}99 und 1{,}00.  
Im Test mit Zwei-Personen-Porträts wurden weiterhin keine False-Positives erkannt, allerdings ebenso einige Gesichter nicht. Der geringst gemessene Wert bei der Gesichtserkennung beträgt 0{,}82. Die Ergebnisse des Tests mit Drei-Personen-Porträts erschweren das Bestimmen eines endgültigen Grenzwertes für \gls{mtcnn}. Der höchst gemessene Wert für False-Positives beträgt 0{,}95, generell haben – wie zuvor erwähnt – alle False-Positives von \gls{mtcnn} sehr hohe \gls{confidence}-Werte. Die Entscheidung, wo der Grenzwert gesetzt werden soll, fällt sehr schwer. Die beiden Möglichkeiten sind 0{,}82 für den minimalen Wert eines erkannten Gesichts oder 0{,}91, um den größten Teil der False-Positives auszusortieren. Der Grund, warum 0{,}82 überhaupt in Erwägung gezogen werden kann, liegt daran, dass die markierten False-Positives bisher immer kleine Bereiche gewesen sind, die ignoriert werden könnten. Der Grenzwert wird vorläufig auf 0{,}82 gesetzt; je nach Ergebnissen wird das Modell mit 0{,}91 Grenzwert getestet und entschieden, welcher Wert verwendet werden soll.
%	
	\item \textbf{Yunet:} Yunet hat bei seinem Einzelporträt-Test keine False-Positives gehabt und ein Gesicht übersehen, ansonsten betrug der minimale Wert für ein erkanntes Gesicht 389{,}12. Der Test mit Zwei-Personen-Porträts verlief mit einem ähnlichen Ergebnis und einem minimalen Wert von 233{,}79. Der letzte \gls{confidence}-Test von Yunet mit Drei-Personen-Porträts ergab weiterhin keine False-Positives und auch den gesamt minimalen Wert für erkannte Gesichter von 154{,}46. Da Yunet wie Dlib \gls{cnn} eher streng zu sein scheint, wird der Grenzwert für Yunet auf 125 gesetzt, um weitere mögliche erkannte Gesichter zuzulassen.
%	
	\item \textbf{RetinaFace (CPU):} RetinaFace hat als minimalen \gls{confidence}-Wert 0{,}74 für Gesichter im Test mit Einzelporträts, ohne Fehler. Die Ergebnisse für Zwei-Personen-Porträts zeigen einen minimalen Wert von 0{,}71 und keine False-Positives, es wurden aber auch manche Gesichter nicht erkannt. Das Ergebnis des Tests mit Drei-Personen-Porträts ist auch gleich dem gesamt minimalen Wert von RetinaFace: 0{,}68 \gls{confidence} für Gesichter und 0{,}52 für Nebengesichter. Da in keinem Test False-Positives markiert wurden, wird der absolut geringst gemessene Wert 0{,}52 als Grenzwert verwendet.
\end{itemize}

%%% Tabele hinzufügen

%\section{Caffe}
%Die Ergebnisse von \gls{caffe} waren bei -1 \gls{confidence} Grenzwert viel zu unkenntlich, also wurde der Test wiederholt. Im zweiten Anlauf wurden alle markieren mit einem \gls{confidence} Wert > 0.1 akzeptiert, da alle Ergebnisse unter diesem Wert aufgrund der riesigen mengen an Flase-Positv unbrauchbar wären.
%Minimaler \gls{confidence} Wert für erkannte Gesichter beim Einzelporträt war 0.11 während der maximale False-Positiv Wert 0.21 ist. Der Wert wurde bei einem Bild gemessen alle anderen erreichten einen Wert von 1.00 oder ca. 0.80. Da nur ein Bruchteil des Cranach Archivs aufgrund der limitierten Zeit getestet werden kann wird der Wert nicht als Ausreißer sondern als gleichwertig betrachtet, da es im restlichen Archiv bestimmt ähnliche Bilder zum 0.11 Kandidaten gibt.
%Ergbenisse des Tests mit Zwei-Personen-Porträts waren deutlich weniger konstant als im letzten Test. Geringster Wert für ein erkanntes Gesicht war 0.14, 0.13 wenn Nebengesichter mitgezählt werden. Allerdings gab es ein großes False-Positv sowohl vom Wert als auch von der Fläche her mit 0.4.
%Der Test mit Drei-Personen-Porträts verlief sehr schlecht für \gls{caffe}. Der geringste erkannte Wert ist 0.1, es ist aber auch sehr wahrscheinlich das der eigentliche Wert noch geringer ist, da in manchen Bilder nicht alle Gesichter erkannt wurden. Auch gab es eine sehr große Menge an False-Positives, höchster Wert in diesem Test 0.28.
%Mit minimaler Geschichtsklitterung \gls{confidence} von 0.1 und maximalem False-Positv \gls{confidence} von 0.4 ist das bestimmen eines optimalen Grenzwertes sehr schwierig. Nach mehreren weiteren Test wurde sich entschieden den Grenzwert auf 0.14 zu setzen. Leider werden damit einige Ergebnisse von erkannten Gesichtern verworfen, allerdings gibt es bis 0.13 noch große mengen an false-positivs, was die gesamt Ergebnisse brauchbarer macht.
%
%\section{Dlib CNN}
%Dlib \gls{cnn}s Tests mit Einzelporträts haben selbst bei einem Grenzwert von -1 keine False-Positives gehabt. Der Minimale Wert für erkannte Gesichter lag bei 1.03.
%Im Test mit Zwei-Personen-Porträts gab es weiter keine Flase-Positives, allerdings wurde auch einige Neben- so wie Hauptgesichter nicht erkannt. 0.70 war der kleinste gemessene Wert für ein Gesicht.
%Weiter werden im Test mit Drei-Personen-Porträts keine False-Positv, aber auch Teils manche Gesichter nicht erkannt. Der geringst gemessene Wert für ein erkanntes Gesicht war in diesem Test 0.97 womit 0.7 der gesamt niedrigste Wert für Dlib \gls{cnn} ist. Da bisher keine False-Positves erkannt und Dlib \gls{cnn} sehr streng scheint, wird der verwendete Grenzwert für Dlib \gls{cnn} 0.6 sein.
%
%\section{MTCNN}
%\gls{mtcnn} ist sehr sicher durch den Test mit Einzelporträts gekommen. Keine False-Positives und und ein minimaler \gls{confidence} Wert bei der Gesichtserkennung von 0.99. Generell sind alle Werte konstant zwischen 0.99 und 1.00.
%Im Test mit Zwei-Personen-Porträts wurden weiter keine Flase-Positives erkannt, allerdings ebenso einige Gesichter nicht. Der geringst gemessene Wert bei der Gesichtserkennung beträgt 0.82. Die Ergebnisse des Tests mit Drei-Personen-Porträts erschweren das bestimmen eines endgültigen Grenzwertes für \gls{mtcnn}. Der höchst gemessene Wert für Flase-Positives beträgt 0.95, generell haben wie zuvor erwähnt alle False-Positives von \gls{mtcnn} sehr hohe \gls{confidence} Werte. Die Entscheidung wo der Grenzwert gesetzt werden soll fällt sehr schwer. Die beiden Möglichkeiten sind 0.82 für den minimalen Wert eines erkannten Gesichts, oder 0.91 um den größten Teil der False-Positives auszusortieren. Der Grund warum 0.82 überhaupt in Erwägung gezogen kann liegt daran das die makierten False-Positives bisher immer kleine Bereiche gewesen sind, die ignoriert werden könnten. Der Grenzwert wird vorläufig auf 0.82 gesetzt, je nach Ergebnissen wird das Modell mit 0.91 Grenzwert getestet und entschieden welcher Wert verwendet werden soll.
%
%\section{Yunet}
%Yunet hat bei seinem Einzelporträt Test keine False-Positives gehabt und ein Gesicht übersehen, ansonsten betrug der minimale Wert für ein erkanntes Gesicht 389.12. Der Test mit Zwei-Personen-Porträts verlief mit einem ähnlichen Ergebnis und einem minimalen Wert von 233.79. Der letzte \gls{confidence} Test von Yunet mit Drei-Personen-Porträts ergab weiter keine False-Positives und auch den gesamt minimal Wert für erkannte Gesichter von 154.46. Da Yunet wie Dlib \gls{cnn} eher streng zu sein scheint, wird der Grenzwert für Yunet auf 125 gesetzt um weitere mögliche erkannte Gesichter zuzulassen.
%
%\section{RetinaFace (CPU)}
%RetinaFace hat als minimalen \gls{confidence} Wert 0.74 für Gesichter im Test mit Einzelporträts, ohne Fehler. Die Ergebnisse für Zwei-Personen-Porträts sind ein minimal Wert von 0.71 und keine False-Positives, es wurden aber auch manche Gesichter nicht erkannt. Ergebnis des Test mit Drei-Personen-Porträts ist auch gleich der gesamt minimal Wert von RetinaFace 0.68 \gls{confidence} für Gesichter und 0.52 für Nebengesichter. Da in keinem Test False-Positives markiert wurden wir der absolut geringst gemessen Wert 0.52 als Grenzwert verwendet.

\section{Vergleich}
Keines der Modelle hat es geschafft, jedes Gesicht aus den bisherigen Tests fehlerfrei zu erkennen. Somit werden im letzten Test alle fünf verbliebenen Modelle gleichzeitig getestet. Dabei werden für jedes Modell die Anzahl von False-Negatives, False-Positives und die Anzahl von Gesichtern, die nur von diesem Modell erkannt wurden, gezählt. Ziel ist es, ein Modell oder eine kleine Auswahl von Modellen herauszuarbeiten, die genutzt werden kann, um so viele Gesichter auf historischen Gemälden wie möglich zu erkennen.

%Tabelle hinzufügen
Die Entscheidung, welches oder welche Modelle sich zur Weiterentwicklung eignen, ist keine leichte, da es kein fehlerfreies Modell gibt, das einfach ausgewählt werden könnte. Auch ist es so, dass es in manchen Bildern vorkommen kann, dass mehrere Gesichter von unterschiedlichen einzelnen Modellen erkannt werden. Es gab bereits die Idee, je nach Bild \gls{confidence} und/oder Modell zu wählen, jedoch bleibt dann weiterhin das Problem bestehen, dass kein einzelnes Modell alle Gesichter eines Bildes erkennt. Die Idee ist es nun, je nach Bild Modelle zu- und abzuschalten, um so mehr Gesichter zu erkennen oder False-Positives auszublenden, wenn ein redundantes Modell gerade nicht benötigt wird. Unter Berücksichtigung des angestrebten Anwendungszwecks fällt die finale Wahl auf: RetinaFace (CPU), \gls{mtcnn} und \gls{cnn}. RetinaFace ist das Modell, welches die wenigsten False-Negatives von allen Modellen hatte. Zusätzlich hat es auch keine False-Positives gehabt, womit es als eine gute Basis dient. \gls{mtcnn} wurde gewählt, da es zusammen mit \gls{cnn} eines der Modelle ist, welches Gesichter markiert hat, die von keinem anderen Modell markiert wurden. Dabei wird der \gls{confidence}-Grenzwert von 0.82 beibehalten, da viele der besonders kleinen Gesichter nur von \gls{mtcnn} erkannt werden und unter den alternativen Wert von 0.91 fallen. Da \gls{mtcnn} abgeschaltet werden kann, falls die False-Positives stören, ist es dennoch eine gute Ergänzung zur Modellauswahl. \gls{cnn} wird aus dem gleichen Grund wie \gls{mtcnn} hinzugezogen. Es hat zwar keine False-Positives, die zu Problemen werden könnten, sollte jedoch nur bei Bedarf eingesetzt werden, da es – wie in vorherigen Tests bereits angemerkt – die Rechenzeit deutlich erhöht. Die Ergebnisse des Modells enthalten, bis auf das gelegentliche Gesicht, das nur davon erkannt wird, oft viele False-Negatives, weswegen es nur situativ benutzt werden sollte.